% notes on Brian's Python + Internet course

16 Jan 2010

At Tully's 4th & Union w/ Brian, Jon Poland, Peter Conerly, Gregg
Toth, new student: Tim Salazar.

Create dropbox account

firstname: Jonathan
lastname: Jacky
email: ...
pw: ...
Computer name: ...

2GB free
Typical setup

https://www.dropbox.com

Puts dropbox notification item on my toolbar, in lrc
So I click on it, it says starting, apparently hangs....

Creates C:\Users\jon\dropbox  with some files and folders

Ok, how do I get the files for the class? What's the folder?

Dropbox help at http://www.dropbox.com/help/16

Now what about setting up a github account, using svn

Github sort of supports svn, but it seems there are limitations.

Just set up github acct on their web page.

https://github.com/signup/free

Username jon-jacky
email ...
password ...

Created public profile

Dashboard is at https://github.com/, help at https://help.github.com/
Nothing about svn on help page.

I installed msysgit months ago - I have git bash shell icon on my toolbar, llc
Open it  - seems to be full-featured bash shell.

I have downloads\git with msysGit-netinstall...exe from 5/13/2010

Brian got me a VM at bluebox, see email today (16 Jan 2010)

username: ...
password: ...
hostname: ...

Use putty to connect, Tully's
Connect to Brian's portable wifi-over-cellphone, name giraffe, pw crazyawesome
Now I can connect to my vm.

Just got Brian's invite to dropbox, accept.

https://www.dropbox.com/home/uwpython#/week1:::28792857

Yes, now I also have C:\Users\jon\dropbox\uwpython\week1 etc.

Back to git ...  follow directions at http://help.github.com/msysgit-key-setup/

I have a ~/.ssh, known_hosts contains seattle.cs.washington.edu and
blackbox.cs.washington.edu

but nothing else - no id_rsa

I didn't select a passphrase, just hit return.

key name is tekkub@gmail.com

Get "successfully authenticated" message.

Okay, I guess I want dirs on VM for various projects, want github repo
to match dirs.   

Next, setting username etc: http://help.github.com/git-email-settings/

In the git bash shell:

jon@LOCKE ~
$ git config --global user.name "jon-jacky"

jon@LOCKE ~
$ git config --global user.email "jon@u.washington.edu"

On github create repository page: https://github.com/repositories/new

Project Name: internet-python

Description: 
Projects for the course, Internet Programming in Python, Winter 2011.

Homepage URL: (left blank)

Who has access? [X] Anyone


It creates repository

git@github.com:jon-jacky/internet-python-.git

What's with the hyphen '-' at the end?  I didn't type this in my repo name!
Argh, there was an extra space at the end. 

Okay, let's delete this and do it over: http://help.github.com/deleting-a-repo/

Yes, now it's: git@github.com:jon-jacky/internet-python.git

Note that there's an option to import an svn repo.

Now make local working directory, mostly following Next steps instructions,
but put it under jon/Documents

jon@LOCKE ~
$ cd Documents/

jon@LOCKE ~/Documents
$ mkdir internet-python

jon@LOCKE ~/Documents
$ cd internet-python

jon@LOCKE ~/Documents/internet-python
$ pwd
/c/Users/jon/Documents/internet-python

jon@LOCKE ~/Documents/internet-python
$ ls

jon@LOCKE ~/Documents/internet-python
$ ls -a
.  ..

jon@LOCKE ~/Documents/internet-python
$ git init
Initialized empty Git repository in c:/Users/jon/Documents/internet-python/.git/


jon@LOCKE ~/Documents/internet-python (master)
$ touch README

jon@LOCKE ~/Documents/internet-python (master)
$ ls
README

jon@LOCKE ~/Documents/internet-python (master)
$ ls -l
total 0
-rw-r--r--    1 jon      Administ        0 Jan 16 21:06 README

jon@LOCKE ~/Documents/internet-python (master)
$ git add README

jon@LOCKE ~/Documents/internet-python (master)
$ git commit -m "first commit: add internet-python/README"
[master (root-commit) 446ee96] first commit: add internet-python/README
 0 files changed, 0 insertions(+), 0 deletions(-)
 create mode 100644 README

jon@LOCKE ~/Documents/internet-python (master)
$ git remote add origin git@github.com:jon-jacky/internet-python.git

jon@LOCKE ~/Documents/internet-python (master)
$ git push origin master
Counting objects: 3, done.
Writing objects: 100% (3/3), 235 bytes, done.
Total 3 (delta 0), reused 0 (delta 0)
To git@github.com:jon-jacky/internet-python.git
 * [new branch]      master -> master

Then click continue on the repository page.  It shows empty README.

Next: edit readme and commit again (or whatever). 

Then, check out repo on VM, Create socket-projects directory.  Begin
to populate it by just copying client and server from dropbox and
running them on VM.

Find tutorials Google: git version control tutorial

https://git.wiki.kernel.org/index.php/GitSvnCrashCourse
https://git.wiki.kernel.org/index.php/GitCheatSheet

This has links to several others, also summary right there on this page

http://help.github.com/git-cheat-sheets/


And man pages (each command linked here)

http://www.kernel.org/pub/software/scm/git/docs/

So, the basic idea is that the repository is *right there in your
working directory*, in .git - that's a whole (local) repository.  Then
you can create a repository elsewhere with git clone, then push to
another repository or pull from another repository.

git add, git commit etc. apply to the local repository, much like svn.
git clone, git push, git pull apply to another repository.

Look at the commands above - that 

git remote add origin
git push origin master

Oh, master is local repository, origin is upstream repository 

git push, git pull are push to/pull from origin

So, we should be able to edit README, commit, then push, and it should
show up on github.

(edit README)

$ git diff
(shows diffs in README)

$ git status
... modified README

jon@LOCKE ~/Documents/internet-python (master)
$ git commit -a -m "add some text to README"
[master 6466d18] add some text to README
 1 files changed, 1 insertions(+), 0 deletions(-)

jon@LOCKE ~/Documents/internet-python (master)
$ git status
# On branch master
nothing to commit (working directory clean)

Refresh github page, nothing new

jon@LOCKE ~/Documents/internet-python (master)
$ git push
Counting objects: 5, done.
Delta compression using up to 2 threads.
Compressing objects: 100% (2/2), done.
Writing objects: 100% (3/3), 325 bytes, done.
Total 3 (delta 0), reused 0 (delta 0)
To git@github.com:jon-jacky/internet-python.git
   446ee96..6466d18  master -> master

Now github page shows revised README commit message and contents

(mkdir notes, cp internet.txt into notes)

$ git add notes

$ git status 

$ git commit -a -m "add notes ..."

(add more text)

jon@LOCKE ~/Documents/internet-python/notes (master)
$ git status
# On branch master
# Changed but not updated:
#   (use "git add <file>..." to update what will be committed)
#   (use "git checkout -- <file>..." to discard changes in working directory)
#
#       modified:   internet.txt
#
no changes added to commit (use "git add" and/or "git commit -a")

jon@LOCKE ~/Documents/internet-python/notes (master)
$ git commit -a -m "revise notes/internet.txt"
[master fc2cf83] revise notes/internet.txt
 1 files changed, 34 insertions(+), 0 deletions(-)

jon@LOCKE ~/Documents/internet-python/notes (master)
$ git push
Counting objects: 9, done.
Delta compression using up to 2 threads.
Compressing objects: 100% (6/6), done.
Writing objects: 100% (8/8), 3.22 KiB, done.
Total 8 (delta 1), reused 0 (delta 0)
To git@github.com:jon-jacky/internet-python.git
   6466d18..fc2cf83  master -> master

Now look on web page, yup it's there.

now mkdir sockets and copy dropbox files:

jon@LOCKE ~/Documents/internet-python/sockets (master)
$ cp ~/Dropbox/uwpython/week1/*.py .

jon@LOCKE ~/Documents/internet-python/sockets (master)
$ ls
week1_echo_client.py  week1_echo_server.py

Now add sockets directory

jon@LOCKE ~/Documents/internet-python (master)
$ git add sockets
warning: LF will be replaced by CRLF in sockets/week1_echo_client.py
warning: LF will be replaced by CRLF in sockets/week1_echo_server.py

Oh dear, well, let's commit.

jon@LOCKE ~/Documents/internet-python (master)
$ git commit -a -m "add sockets directory with echo client and server from drop
box"
[master d5e48a7] add sockets directory with echo client and server from dropbox
warning: LF will be replaced by CRLF in sockets/week1_echo_client.py
warning: LF will be replaced by CRLF in sockets/week1_echo_server.py
 3 files changed, 71 insertions(+), 0 deletions(-)
 create mode 100644 sockets/week1_echo_client.py
 create mode 100644 sockets/week1_echo_server.py

jon@LOCKE ~/Documents/internet-python (master)
$ git push
Counting objects: 10, done.
Delta compression using up to 2 threads.
Compressing objects: 100% (6/6), done.
Writing objects: 100% (7/7), 1.29 KiB, done.
Total 7 (delta 1), reused 0 (delta 0)
To git@github.com:jon-jacky/internet-python.git
   fc2cf83..d5e48a7  master -> master

Next, clone on vm, run server there, run client in local git master.

see if svn is running on vm, so we can do svn log pager there.
 

17 Jan 2011

Try week1_echo_client/server.py from dropbox on HP notebook as localhost.

Run server: windows firewall blocks, I have to unblock.
Run client, fails, 'request address is not valid...', host is ''

In client change host to 'localhost', ditto server.
Must close cmd window to kill server, it doesn't respond to ^C

Dropbox server version currently just responds "foobar", not with echo, fix.
Now it works as it should.  Commit and push.

C:\Users\jon\Documents\internet-python\sockets>git commit -a -m "week1_echo_clie
nt,server.py now working as intended, fix problems in dropbox versions"
warning: LF will be replaced by CRLF in sockets/week1_echo_client.py
warning: LF will be replaced by CRLF in sockets/week1_echo_server.py
[master warning: LF will be replaced by CRLF in sockets/week1_echo_client.py
warning: LF will be replaced by CRLF in sockets/week1_echo_server.py
f9ffb69] week1_echo_client,server.py now working as intended, fix problems in dr
opbox versions
warning: LF will be replaced by CRLF in sockets/week1_echo_client.py
warning: LF will be replaced by CRLF in sockets/week1_echo_server.py
 3 files changed, 20 insertions(+), 7 deletions(-)

C:\Users\jon\Documents\internet-python\sockets>git push
Counting objects: 13, done.
Delta compression using up to 2 threads.
Compressing objects: 100% (6/6), done.
Writing objects: 100% (7/7), 939 bytes, done.
Total 7 (delta 3), reused 0 (delta 0)
To git@github.com:jon-jacky/internet-python.git
   dac45d7..f9ffb69  master -> master

Again, this LF -> CRLF warning ...  Will that be a problem on VM?

Now log into VM, git clone, and run the echo server there.

putty jon@block115406-urm.blueboxgrid.com

Using username "jon".
jon@block115406-urm.blueboxgrid.com's password:
Linux block115406-urm.blueboxgrid.com 2.6.18-194.8.1.el5.028stab070.5 #1 SMP Fri Sep 17 19:10:36 MSD 2010 i686 GNU/Linux
Ubuntu 10.04.1 LTS

Welcome to Ubuntu!
 * Documentation:  https://help.ubuntu.com/

*** System restart required ***
Last login: Mon Jan 17 00:16:37 2011 from 184.234.233.107
jon@block115406-urm:~$ ls -a
. .. .bash_history (... etc. ...)

What's with "system restart" - ?

Right-click in top bar of window to get menu, 
in Settings -> appearance -> font, change from 10pt to 14pt.

Get pop-up notice: two files removed from dropbox.  They are they
week1_echo_client/server.py - !?   did I move them out rather than copy
them?  I'm pretty sure I copied them...  Oh, forget it, there is also 

https://github.com/briandorsey/uwpython_web/blob/master/week01/echo_client.py
etc.  - which looks right.

Ok, it looks like what I want to do on vm is:

 git clone https://github.com/jon-jacky/internet-python/ internet-python

There doesn't seem to be any way to cut from/paste to putty window.

Try it.  

fatal: https://github.com/jon-jacky/internet-python/info/refs not found: did you run git update-server-info on the server?

Should this be necessary to do git clone?  Oh, but maybe that's not
the right URL.  According to https://git.wiki.kernel.org/index.php/GitCheatSheet
I should be cloning the hole repository URL, ends with .git

$ git clone https://github.com/jon-jacky/internet-python.git
Initialized empty Git repository in /home/jon/internet-python/.git/
...
.., done.

Yes, now I have internet-python directory with expected contents.
Now echo server has localhost hard coded - open another putty window to 
vm.  Yes, it works.

Now on HP localhost, make sum_server and sum_client based on echo_...

Looked at http://groups.google.com/group/uwpython2010/topics?hl=en
lots of people are having difficulties with dropbox and git.

In local git, .../internet-python/sockets/ on HP, make sum_server,client.py
minimal versions based on echo sample with hardcoded localhost, port 50000,
numbers 1 2.  Works.

git commit, git push, on vm git pull.  They're there and they work.
Now make versions where host, port, numbers are cmd line args
also write progress messages to console from both client and server.
Then git commit -a -m ...; git push

Now git pull on vm.  Start server there.


Now on my own machine, try to run client:


C:\Users\jon\Documents\internet-python\sockets>python sum_client.py block115406-
urm.blueboxgrid.com 50000
Traceback (most recent call last):
  File "sum_client.py", line 38, in <module>
    s.connect((host,port))
  File "<string>", line 1, in connect
socket.error: [Errno 10061] No connection could be made because the target machine actively refused it

Server echoes nothing.  Maybe it doesn't like that port number?  Try
8080 on server.  No, still "actively refused" connection requests.

Try both client and server on vm localhost also.  Yes, that works.

Is a firewall running?  Google finds page that says ufw is the default
firewall for ubuntu:

https://help.ubuntu.com/community/UFW

But 

$ sudo ufw status
sudo: ufw: command not found

Is it something else like ipfw?  Yes, looking at bluebox support page

https://boxpanel.bluebox.net/public/the_vault/index.php/Main_Page

points to 

https://boxpanel.bluebox.net/public/the_vault/index.php/Firewall_Configuration

They're using iptables for firewall.  Try iptables --help.  Then try
 iptables --list or --list-rules, get: "... Permission denied: you must be root"

Okay, that's enough for tonight.


18 Jan 2011

Can we sudo ... ?

 $ sudo iptables --list
Chain INPUT (policy ACCEPT)   
target  pro opt source          destination

Chain FORWARD (policy ACCEPT)
... the same ...

Chain OUTPUT (policy ACCEPT)
...

So it looks like there aren't any rules - this isn't the problem.

$ sudo iptables --list-rules
-P INPUT ACCEPT
-P FORWARD ACCEPT
-P OUTPUT ACCEPT

That's all ...

Now this morning I start server on vm and try connecting through Allegro wifi:

C:\Users\jon\Documents\internet-python\sockets>python sum_client.py jon@block115
406-urm.blueboxgrid.com 50000
Traceback (most recent call last):
  File "sum_client.py", line 38, in <module>
    s.connect((host,port))
  File "<string>", line 1, in connect
socket.gaierror: [Errno 11003] getaddrinfo failed

So this looks like *another* problem, I suspect the router here at the
Allegro won't let socket traffic through.

JC got his working where he used the bluebox hostname (not localhost) on the *server* side.

Yes, this works, run server on VM:

 $ python sum_server.py "block115406-urm.blueboxgrid.com"
...

run client on laptop:

 > python sum_client.py block115406-urm.blueboxgrid.com 50000 8 7
Send numbers: 8.0 7.0
Receive sum: 15.0

It works! Thanks to Jon Crump.


29 Jan 2011

Looking for mashup project for week 3.  Thought I might use
BeautifulSoup to get links and annotations from my links.html, use an
API to put links with captions and tags derived from annotations on
delicious.

Delicious might be going away soon, but this is just an exercise - if
we get this working we might use another site.

Delicious' API page describes an HTTP API - how to construct URLS with
&'s etc., gahh...  

http://www.delicious.com/help/api

Google turns up a few Python wrappers for their API, not from Google,
but they haven't been maintained for a few years...  One is just for
getting stuff off delicious, not for putting stuff on.  

http://www.michael-noll.com/projects/delicious-python-api/

Another one warns that it doesn't work with current delicious
authorization scheme, bah.

http://code.google.com/p/pydelicious/

Investigate delicious replacements to see if any have a friendlier
python API.  According to MeFi and HN, the most popular one might be
Pinboard.  

http://searchyc.com/delicious+replacement

http://ask.metafilter.com/173315/stumbleupon-any-other-delicious-magnolias-lately

Pinboard calls their site "antisocial bookmarking - social bookmarking
for introverts ... a low-noise bookmarking site".  Cute, but it costs
to sign up.  Not much - $9.21 - but no good for experimenting.  And,
their API is just a copy of delicious', they even link to the
delicious API page!

http://pinboard.in/howto/#api

Then there's Google Bookmarks.  

https://www.google.com/bookmarks/l

But it's not listed at the Google API page

http://code.google.com/more/table/

there is apparently no published API, this guy reverse-engineered some of it.

http://www.mmartins.com/mmartins/googlebookmarksapi/

Maybe this isn't such a good project idea anyway - there is a
supported way to import bookmarks.  

http://www.google.com/support/bookmarks/bin/answer.py?answer=178166

that is, in Firefox import bookmarks (page of HTML) and then just use
a tool to upload that to Google Bookmarks, no doubt delicious
etc. provide something similar.

Years ago I recall I created a delicious account but never posted
anything.  Indeed, there is http://www.delicious.com/jacky/ "Jacky has
not bookmarks .. yet!"  Log in as jackyj with usual pw - it works!
"Hi, jackyj".  Click "save a bookmark", enter http://staff.washington.edu/jon/
Add tags: people UW work  Notes: My home page at the University of Washington
But nothing shows up on Jacky's Bookmarks page, refresh page ... nothing.
Give it some time.

Oh, I have to click on bookmarks, then I have the one I just posted, also
three from 23 Oct 04: Phile Agre, Peter Norvig, Paul Graham.  
This is at http://www.delicious.com/jackyj not /jacky.  When I sign in again 
as jackyj, I see my pages.

Can I use an API to post a page?  Let's try pydelicious, from Google
Code or PyPI.  Download pydelicious-0.6.zip from 
http://code.google.com/p/pydelicious/downloads/list
extract to to C:\downloads\pydelicious\pydelicious-0.6, read README.rst there.

 > python setup.py install
... apparently succeeds ...

Then back in my own dirs:

C:\Users\jon\Documents\internet-python>python
Python 2.6.2 (r262:71605, Apr 14 2009, 22:40:02) [MSC v.1500 32 bit (Intel)] on
win32
Type "help", "copyright", "credits" or "license" for more information.
>>> from pydelicious import DeliciousAPI
Feedparser not available, no RSS parsing.
>>> dir()
['DeliciousAPI', '__builtins__', '__doc__', '__name__', '__package__']
>>> dir(DeliciousAPI)
['__doc__', '__init__', '__module__', '__repr__', 'bundles_all', 'bundles_delete
', 'bundles_set', 'get_method', 'get_url', 'paths', 'posts_add', 'posts_all', 'p
osts_dates', 'posts_delete', 'posts_get', 'posts_recent', 'posts_update', 'reque
st', 'request_raw', 'tags_delete', 'tags_get', 'tags_rename']
>>>

Looks like we got it.  README.rst has example of using it from python cmd.
Also there's a shell dlcs - how do we run that?

C:\Python26\Lib\site-packages\pydelicious 

has only __init__.py and .pyc.  But we also have

C:\downloads\pydelicious\pydelicious-0.6\tools\dlcs.py

Try it:

C:\downloads\pydelicious\pydelicious-0.6\tools>python dlcs.py
Feedparser not available, no RSS parsing.
No JSON decoder installed
Traceback (most recent call last):
  File "dlcs.py", line 1202, in <module>
    _main()
  File "dlcs.py", line 1196, in _main
    sys.exit(main(sys.argv[1:]))
  File "dlcs.py", line 380, in main
    opts['username'] = os.getlogin()
AttributeError: 'module' object has no attribute 'getlogin'

C:\downloads\pydelicious\pydelicious-0.6\tools>python
Python 2.6.2 (r262:71605, Apr 14 2009, 22:40:02) [MSC v.1500 32 bit (Intel)] on
win32
Type "help", "copyright", "credits" or "license" for more information.
>>> import os
>>> dir(os)
... 
, 'extsep', 'fdopen', 'fstat', 'fsync', 'getcwd', 'getcwdu', 'getenv', 'getpid',
...

But no getlogin.  So it looks like we can't run dlcs on Windows.

Okay, what about running the API from the shell like in the README.rst.

>>> from pydelicious import DeliciousAPI; from getpass import getpass
Feedparser not available, no RSS parsing.
>>> pwd = getpass('Pwd:')
Pwd:
>>> a = DeliciousAPI('user', pwd)
>>> a
DeliciousAPI(user)
>>> a.tags_get()
Traceback (most recent call last):
 ...
 ... lots omitted ...
 ...
  File "C:\Python26\lib\site-packages\pydelicious\__init__.py", line 182, in htt
p_error_401
    raise PyDeliciousUnauthorized, "Check credentials."
pydelicious.PyDeliciousUnauthorized: Check credentials.
>>>

Oh dear.  Am I running into this problem, noted on 
http://code.google.com/p/pydelicious/

IMPORTANT: pydelicious has not been updated to use the OAuth
protocol. New users with a Yahoo account/email will not be able to use
this library.

Oh, no, I was meant to put my own username instead of 'user'

>>> a = DeliciousAPI('jackyj', pwd)
>>> a.tags_get()
{'tags': [{'count': '1', 'tag': 'ai'}, {'count': '1', 'tag': 'business'}, {'coun
...

It worked!


It worked! Try this ---

>>> a.posts_add("http://staff.washington.edu/jon/links.html", "Interesting web s
ites", extended="Here are some interesting sites that are not directly related t
o my work or my teaching.", tags="search reference directories dictionaries thes
auri current-events politics arts culture science research math logic engineerin
g technology education graphics design programming software internet security pr
ivacy miscellaneous toread")

That worked too!  That bookmark is now on my delicious page.

30 Jan 2011

Now let's work on the BeautifulSoup side. First let's get the page into Python:

C:\Users\jon\Documents\internet-python\mashup>python
...
>>> fd = open("..\..\www\links.html")
>>> page = fd.read()
>>> len(page)
297346
>>> print page[0:20]
<html>
<head>
<link
>>>

The page is large but we can print selected parts, as above.  The
print statement observes linebreaks.

This page is so large, let's write a script that just uploads links i:j.
That way we can check/demo in small increments, not the whole file at once.
Also have a switch to TURN OFF actual upload, for testing and trials.

We want all the href links that are http not #... internal links.  we
want the link attributes in href="..." not the link text between
open/close tag.

Each link appears in a paragraph.  Use the text at the beginning of
the paragraph (before the first href) as the extended=... arg. to
posts_add.  For tags, I'd like to use each word that appears in an h2,
h2, ... tag (down to ).  Except the words in notag (split on space):

notag "the and but a always other more also works in a category by themselves"

Then if tags are empty ("in a category by themselves") use "miscellaneous"

Some phrases will be unavoidably split: "Search engines" "Current
events" "Graduate school".  Possibly put second tag word in notage:
"engines events".  Yes.

First with BeautfulSoup, see if we can just print out all the <h2>,<h3>,<p>,
and <href>.  Read how:

 http://www.crummy.com/software/BeautifulSoup/documentation.htm

>>> from BeautifulSoup import BeautifulSoup
>>> soup = BeautifulSoup(page)

>>> print soup.findAll(h2)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'h2' is not defined

Huh?  I just copied their example.  I had this problem in class too...
DOH!  It's findAll not findall

>>> soup.findAll('h2')
[<h2>Interesting web sites</h2>, <h2><a name="dir">
Search engines, directories, and reference works</a></h2>, <h2><a name="words">W
ords: dictionaries, thesauri, and more</a></h2>, <h2><a name="news">Current even
...
...]
>>> hrefs = soup.findAll('href')
>>> len(hrefs)
0

href is not a tag, 'a' is the tag: <a href=... ...>...</a>

>>> pars = soup.findAll('p')
>>> len(pars)
647
>>> as = soup.findAll('a')
  File "<stdin>", line 1
    as = soup.findAll('a')
     ^
SyntaxError: invalid syntax
>>> anchors = soup.findAll('a')
>>> len(anchors)
2144

Wow! I have ~ 2000 links! (some of those are href="#..." internal links)

We want do do depth-first traverse of whole page and case branch on
each element, only elements that matter are h2, h3, p, a

 if tag == h2:
   keywords = get_keywords(h2.contents) # what delicious calls tags
   keywords.insert(0, []) # dummy h3 
 elif tag == h3: 
   keywords.pop() 
   keywords.insert(0, get_keywords(h3.contents))
 elif tag == p:
   extended = get_description(p.contents)
 elif tag = a and href and http:
   upload_link(a.link, extended, keywords)

Need logic in here to control whether/how many links to send

This script should also handle svn diff output, so we could incrementally
upload new additions.

BeautifulSoup handles tag attributes like dictionary keys:

>>> soup.find('a')
<a href="http://staff.washington.edu/~jon/">my work</a>
>>> anchor = soup.find('a')
>>> anchor['href']
u'http://staff.washington.edu/~jon/'
>>> anchor.attrs
[(u'href', u'http://staff.washington.edu/~jon/')]
>>> anchor.contents
[u'my work']

That u'...' is because BeautifulSoup treats all strings as Unicode.

>>> para  = soup.find('p')
>>> para
<p>
Here are some interesting sites that are not directly related to
<a href="http://staff.washington.edu/~jon/">my work</a> or
<a href="http://staff.washington.edu/jon/python-course/">my teaching</a>.
<!--
(<a href="http://academic.evergreen.edu/curricular/fofc00/">etc.</a>)
-->
</p>
>>> para.attrs
[]
>>> para.contents
[u'\nHere are some interesting sites that are not directly related to\n', <a hre
f="http://staff.washington.edu/~jon/">my work</a>, u' or\n', <a href="http://sta
ff.washington.edu/jon/python-course/">my teaching</a>, u'.\n', u'\n(<a href="htt
p://academic.evergreen.edu/curricular/fofc00/">etc.</a>)\n', u'\n']
>>> para.contents[0]
u'\nHere are some interesting sites that are not directly related to\n'

>>> h2=soup.find('h2')
>>> h2
<h2>Interesting web sites</h2>
>>> h2.contents
[u'Interesting web sites']
>>> h2.contents[0]
u'Interesting web sites'

>>> h3=soup.find('h3')
>>> h3
<h3><a name="news-now">Now</a></h3>
>>> h3.contents
[<a name="news-now">Now</a>]

Right, h2 and h3 contents aren't the contents of the subsection, just
the tag itself between <hi>...</hi>.  IN the h3 case the contents
isn't a string, it's another tag, the 'a' tag.  Oh dear, I've got
those in some but not all h2 and h3, and also in some p, makes them
irregular.  This would turn into a typical scraper with lots of
special case handling ...

"For your convenience, if a tag has only one child node, and that
child node is a string, the child node is made available as
tag.string, as well as tag.contents[0]."

>>> h2.string
u'Interesting web sites'
>>> anchor.string
u'my work'
>>> para.string
>>> h3.string
>>>

So we could have 'if elt.string: ...' for typical case

How to traverse...


